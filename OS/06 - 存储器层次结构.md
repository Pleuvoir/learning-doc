## 存储器层次结构

从 CPU 的角度看是从内存加载或者写入数据。主存是有多个芯片（内存条）组成的。

SRAM 容量小，速度快 -》 高速缓存
DRAM -》 主存

### CPU 读主存

以一个加载操作举例`movp A,%rax`：

该指令想把地址 A 的数据加载到寄存器%rax 中。流程如下：

CPU 将 A 地址复制到`系统总线`，然后 IO 桥将地址传递到`内存总线`，内存总线根据该地址从内存获取对应的数据。然后从内存条读取数据按下面顺序返回

内存总线-》IO 桥接器-》系统总线-》CPU 获取数据复制到寄存器

### CPU 写主存

写操作举例`movp &rax,A`：

代表将寄存器的值保存到内存条中，顺序如下：

CPU-》复制数据要保存的地址 A 到系统总线-》通过 IO 桥接器移动到内存总线-》内存总线感知到要接收数据放在 A 处-》CPU 复制寄存器的值到系统总线-》通过 IO 桥移动到内存总线-》然后保存到内存条中

`IO桥接器`就是让`系统总线、内存总线、IO总线`沟通的枢纽。

### 读写磁盘

从磁盘读取数据比从内存读慢 100W 倍的数量级，以`ms`为单位。

CPU 从磁盘以块的单位读取，磁盘控制器负责转换这种关系。

读取文件时操作系统其实是从文件缓存中读的而不是磁盘。文件缓存也是文件的一部分，文件缓存在主存中。

### 直接内存访问 DMA

CPU 从磁盘读数据举例：

CPU 使用内存映射的方式，在地址空间里维护了各个 IO 设备的端口信息，不是 8080 这种，而是一个地址。每个 IO 设备连接到 IO 总线的时候会至少会映射一个端口。这样当 CPU 想从磁盘读取的时候直接往磁盘内存映射端口上写一些要读取的逻辑块号、目标地址啥的。然后磁盘控制器就把数据搞到主存中去。当它搞完以后再用中断的形式通知 CPU。这样 CPU 就知道数据已经到它想要的地方了。

总结一下，整个读取过程是 CPU 在内存映射中写了我想要什么数据放到哪，然后就不管了，过一会磁盘管理器把安排好了再通过中断回调 CPU。

科学的定义：设备可以自己执行读写总线事务而不需要 CPU 干预叫`DMA`。

注意：DMA 读取书库不需要 CPU 参与指的是数据流不经过 CPU，而不是 CPU 不发指令。

正常是键盘输入先到达 CPU 寄存器然后才到内存中的。

### 虚拟内存

虚拟内存时让进程以为它独占主存，实现时将这部分程序数据保存在磁盘，高速缓存中保存部分数据。

### 局部性原理

- 时间局部性 很简单就是 for 循环，程序倾向使用之前使用过的元素
- 空间局部性 通用的以块作为数据单位进行传输，但是一个块包含多个数据对象。充分利用空间局部性就能补偿没有命中复制该块带来的花费。步长为 1 最优，按照行优先顺序

数组应该是以行优先进行排序的，保证行以最快的速度切换。避免在内存中跳跃，最好是步长为 1 的访问模式。

结论：按照 a[i][j][p]

```
for i
	for j
		for p
```

始终保证步长为 1 不要乱跳。

#### 缓存

因为局部性原理，计算机的设计中也有了缓存的施展之地。

冷不命中 - 需要预热
容量不命中-大小不够
冲突不命中-假设告诉缓存只有 4 个块（比如 hash mod 4）取块 4 8 12 =0 位置，每次都会驱逐原有的值。

### 其它

PCI 总线也被称为数据广播总线，任何一个线上数据都能被其它设备看见。

单核处理器采用模拟多线程的方式。

由于 CPU 运算速度越快功率越高（太烫了），所以通过增加核数进行并行。

超线程技术目前一次可跑两个。所以 CPU 支持的核心数\*2 得到支持的线程数。怎么实现的呢？核心有多个程序计数器 PC 寄存器，而传统的核心只有一个程序计数器和 PC 寄存器。所以本质上还是通过冗余部分硬件实现的。

CPU 指令通过流水线技术，可达到一个时钟周期一个指令，分阶段跑指令。
